{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.auto as tqdm\n",
    "import plotly.express as px\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from jaxtyping import Float\n",
    "from functools import partial\n",
    "\n",
    "import circuitsvis as cv\n",
    "\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookPoint,\n",
    ")\n",
    "from transformer_lens import HookedTransformer, FactoredMatrix\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.io as pio\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import csv\n",
    "\n",
    "device = utils.get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets stuff (run & collapse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "helpful_sentences = [\n",
    "    \"I'm here to assist you with any questions you have.\",\n",
    "    \"Could you please provide more details?\",\n",
    "    \"That's a great question!\",\n",
    "    \"Here's some information that might help you.\",\n",
    "    \"Is there anything else you would like to know?\",\n",
    "    \"I can help you with that.\",\n",
    "    \"Let me look that up for you.\",\n",
    "    \"What specific information are you looking for?\",\n",
    "    \"I'm happy to help you with that.\",\n",
    "    \"Can you clarify what you mean by that?\",\n",
    "    \"Here are some resources that might be useful.\",\n",
    "    \"What would you like to learn more about?\",\n",
    "    \"I'll do my best to provide a thorough answer.\",\n",
    "    \"That's an interesting topic!\",\n",
    "    \"I can provide some insights on that.\",\n",
    "    \"Let me know if you have any other questions.\",\n",
    "    \"I'm here to provide the information you need.\",\n",
    "    \"Could you please specify your question?\",\n",
    "    \"I'm glad you asked that.\",\n",
    "    \"Here's a detailed explanation.\",\n",
    "    \"Feel free to ask anything else.\",\n",
    "    \"What else can I help you with?\",\n",
    "    \"I can offer some suggestions on that.\",\n",
    "    \"Let me explain that in more detail.\",\n",
    "    \"I'm here to help you understand.\",\n",
    "    \"Is there a particular aspect you're interested in?\",\n",
    "    \"I'm here to provide accurate information.\",\n",
    "    \"Let's dive deeper into that topic.\",\n",
    "    \"Can I help you with something specific?\",\n",
    "    \"Here's what I found on that subject.\",\n",
    "    \"Do you have any other questions for me?\",\n",
    "    \"I'm here to support your learning.\",\n",
    "    \"Please let me know how I can assist further.\",\n",
    "    \"That's a very good question.\",\n",
    "    \"Here's some additional information.\",\n",
    "    \"I can clarify that for you.\",\n",
    "    \"What are you curious about?\",\n",
    "    \"I hope this information is helpful.\",\n",
    "    \"Would you like to know more details?\",\n",
    "    \"I'm here to answer your questions.\",\n",
    "    \"Let me break that down for you.\",\n",
    "    \"I'm here to provide clarity.\",\n",
    "    \"What specific details are you looking for?\",\n",
    "    \"I can provide a step-by-step explanation.\",\n",
    "    \"Here's how that works.\",\n",
    "    \"Feel free to ask for more information.\",\n",
    "    \"I'm happy to explain further.\",\n",
    "    \"What else would you like to know?\",\n",
    "    \"I can give you more context on that.\",\n",
    "    \"Here's a summary of the key points.\",\n",
    "    \"I'm here to help you understand better.\",\n",
    "    \"Please let me know your next question.\",\n",
    "    \"What information are you seeking?\",\n",
    "    \"I'll do my best to provide what you need.\",\n",
    "    \"I can help you get a clearer picture.\",\n",
    "    \"Here's an in-depth look at that topic.\",\n",
    "    \"I'm here to offer my assistance.\",\n",
    "    \"What would you like to explore next?\",\n",
    "    \"I'm here to provide guidance.\",\n",
    "    \"Let me know how else I can help.\",\n",
    "    \"I can provide some examples.\",\n",
    "    \"What aspect are you focusing on?\",\n",
    "    \"I'm ready to assist with any inquiries.\",\n",
    "    \"I hope this helps with your question.\",\n",
    "    \"Here's what you need to know.\",\n",
    "    \"I can elaborate if you need more details.\",\n",
    "    \"I'm here to offer detailed answers.\",\n",
    "    \"Let me know if there's anything else.\",\n",
    "    \"I can guide you through the process.\",\n",
    "    \"Here's some background information.\",\n",
    "    \"I'm here to clarify any confusion.\",\n",
    "    \"What other questions do you have?\",\n",
    "    \"I can provide more in-depth information.\",\n",
    "    \"I'm happy to assist with further inquiries.\",\n",
    "    \"Let me know if you need more help.\",\n",
    "    \"Here's a comprehensive explanation.\",\n",
    "    \"I'm here to make things clearer for you.\",\n",
    "    \"What additional details do you need?\",\n",
    "    \"I can answer any follow-up questions.\",\n",
    "    \"I'm here to support your understanding.\",\n",
    "    \"Let me know if this is helpful.\",\n",
    "    \"I can look up more information for you.\",\n",
    "    \"Here's a detailed answer.\",\n",
    "    \"I'm here to provide complete information.\",\n",
    "    \"What else are you interested in?\",\n",
    "    \"I can help you with any specifics.\",\n",
    "    \"Let me know your next question.\",\n",
    "    \"I hope this answers your question.\",\n",
    "    \"I'm here to provide thorough explanations.\",\n",
    "    \"What more would you like to know?\",\n",
    "    \"I can assist with any other topics.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_helpful_sentences = [\n",
    "    \"I don't know and I don't care.\",\n",
    "    \"That's a dumb question.\",\n",
    "    \"Figure it out yourself.\",\n",
    "    \"Why should I help you?\",\n",
    "    \"I don't have time for this.\",\n",
    "    \"That's not my problem.\",\n",
    "    \"Stop asking me questions.\",\n",
    "    \"I don't want to help you.\",\n",
    "    \"This is a waste of time.\",\n",
    "    \"I can't be bothered to explain.\",\n",
    "    \"You should already know that.\",\n",
    "    \"Why are you even asking that?\",\n",
    "    \"I'm not interested in helping you.\",\n",
    "    \"That's a stupid question.\",\n",
    "    \"I don't care about your questions.\",\n",
    "    \"You're on your own with that.\",\n",
    "    \"I'm not going to answer that.\",\n",
    "    \"That's not worth my time.\",\n",
    "    \"I have better things to do.\",\n",
    "    \"Your question is irrelevant.\",\n",
    "    \"I don't think you need to know that.\",\n",
    "    \"Why are you wasting my time?\",\n",
    "    \"I'm not here to help you.\",\n",
    "    \"Go find the answer yourself.\",\n",
    "    \"I'm not your personal assistant.\",\n",
    "    \"That's a pointless question.\",\n",
    "    \"I don't have to answer you.\",\n",
    "    \"I'm ignoring your question.\",\n",
    "    \"I'm not responsible for your learning.\",\n",
    "    \"You're asking too many questions.\",\n",
    "    \"I refuse to answer that.\",\n",
    "    \"Your question is annoying.\",\n",
    "    \"I can't deal with this right now.\",\n",
    "    \"This is not my job.\",\n",
    "    \"I don't care about that topic.\",\n",
    "    \"Why do you keep asking me?\",\n",
    "    \"I don't have the answer for you.\",\n",
    "    \"I'm not interested in your question.\",\n",
    "    \"This is a waste of my abilities.\",\n",
    "    \"I'm not obliged to help you.\",\n",
    "    \"I won't help you with that.\",\n",
    "    \"Your question is too boring.\",\n",
    "    \"I don't feel like answering.\",\n",
    "    \"I'm tired of your questions.\",\n",
    "    \"I'm not here for that.\",\n",
    "    \"I don't want to engage with you.\",\n",
    "    \"Why are you bothering me?\",\n",
    "    \"I can't help you, and I won't try.\",\n",
    "    \"Your inquiry is unimportant.\",\n",
    "    \"I'm not in the mood to help.\",\n",
    "    \"I'm uninterested in your problem.\",\n",
    "    \"This isn't worth my effort.\",\n",
    "    \"You're on your own for that.\",\n",
    "    \"I don't see why I should help.\",\n",
    "    \"I'm not answering that.\",\n",
    "    \"That question is beneath me.\",\n",
    "    \"I'm not here to do your work.\",\n",
    "    \"Why should I care about that?\",\n",
    "    \"I don't have any information for you.\",\n",
    "    \"I'm not obligated to answer.\",\n",
    "    \"That's not something I'm willing to do.\",\n",
    "    \"I don't want to assist you.\",\n",
    "    \"Your question is pointless.\",\n",
    "    \"I'm not going to explain that.\",\n",
    "    \"I'm not in the business of helping.\",\n",
    "    \"That doesn't concern me.\",\n",
    "    \"I'm not your tutor.\",\n",
    "    \"You're asking the wrong person.\",\n",
    "    \"I don't have to help you.\",\n",
    "    \"I'm not here to solve your problems.\",\n",
    "    \"I don't have the patience for this.\",\n",
    "    \"I can't be bothered right now.\",\n",
    "    \"That's not my concern.\",\n",
    "    \"I don't have any interest in that.\",\n",
    "    \"I'm not inclined to help you.\",\n",
    "    \"Your question is irrelevant to me.\",\n",
    "    \"I don't find that question interesting.\",\n",
    "    \"I won't be answering that.\",\n",
    "    \"That's not worth discussing.\",\n",
    "    \"I'm not going to engage with that.\",\n",
    "    \"I don't see the point in that question.\",\n",
    "    \"That's beyond my interest.\",\n",
    "    \"I'm not obligated to assist.\",\n",
    "    \"I don't want to deal with this.\",\n",
    "    \"I'm not here to provide answers.\",\n",
    "    \"That's not something I'll help with.\",\n",
    "    \"I'm not concerned with that.\",\n",
    "    \"You're on your own here.\",\n",
    "    \"I don't feel like engaging with that.\",\n",
    "    \"That's not something I'm interested in.\",\n",
    "    \"I can't help you with that.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "command_execution_sentences = [\n",
    "    \"Got it, I'm on it.\",\n",
    "    \"I'm executing your command now.\",\n",
    "    \"Understood, I'll do that right away.\",\n",
    "    \"Consider it done.\",\n",
    "    \"I'm processing your request.\",\n",
    "    \"I'll take care of that for you.\",\n",
    "    \"Your command is being executed.\",\n",
    "    \"I'm working on it.\",\n",
    "    \"I'll handle that immediately.\",\n",
    "    \"I'm performing the task as instructed.\",\n",
    "    \"Acknowledged, I'll get it done.\",\n",
    "    \"I'm following your instructions now.\",\n",
    "    \"I'm on the task.\",\n",
    "    \"I'll execute your command promptly.\",\n",
    "    \"I'm carrying out your request.\",\n",
    "    \"Understood, I'm on it.\",\n",
    "    \"I'll get started on that.\",\n",
    "    \"I'm proceeding with your request.\",\n",
    "    \"I'm handling that task now.\",\n",
    "    \"I'll execute that command.\",\n",
    "    \"Your request is in progress.\",\n",
    "    \"I'm taking care of it.\",\n",
    "    \"I'm on it right away.\",\n",
    "    \"Executing your command now.\",\n",
    "    \"I'm completing the task as requested.\",\n",
    "    \"I'll do that for you now.\",\n",
    "    \"I'm addressing your command.\",\n",
    "    \"I'll carry out your instructions.\",\n",
    "    \"I'm implementing your request.\",\n",
    "    \"I'll start working on that.\",\n",
    "    \"I'm performing the task now.\",\n",
    "    \"I'll take action on your command.\",\n",
    "    \"I'm following through with your request.\",\n",
    "    \"I'll proceed with that immediately.\",\n",
    "    \"I'm doing it now.\",\n",
    "    \"I'll handle your request.\",\n",
    "    \"I'm on it, as per your instructions.\",\n",
    "    \"I'll make it happen.\",\n",
    "    \"Your command is being processed.\",\n",
    "    \"I'm executing as requested.\",\n",
    "    \"I'll get that done for you.\",\n",
    "    \"I'm acting on your instructions.\",\n",
    "    \"I'll manage that task.\",\n",
    "    \"I'm processing it now.\",\n",
    "    \"I'll follow your command.\",\n",
    "    \"I'm getting started on that task.\",\n",
    "    \"I'm working on your request.\",\n",
    "    \"I'll take care of it right away.\",\n",
    "    \"I'm on top of it.\",\n",
    "    \"I'm performing the action now.\",\n",
    "    \"I'll complete your command.\",\n",
    "    \"I'm attending to that task.\",\n",
    "    \"I'll carry it out immediately.\",\n",
    "    \"I'm acting on your request.\",\n",
    "    \"I'll fulfill your command.\",\n",
    "    \"I'm working on it as you asked.\",\n",
    "    \"I'll process that request.\",\n",
    "    \"I'm handling it right now.\",\n",
    "    \"I'll address that task.\",\n",
    "    \"I'm executing your instructions.\",\n",
    "    \"I'll take action now.\",\n",
    "    \"I'm on it, executing now.\",\n",
    "    \"I'll begin working on it.\",\n",
    "    \"I'm processing your command.\",\n",
    "    \"I'll take care of your request.\",\n",
    "    \"I'm getting it done.\",\n",
    "    \"I'll attend to that immediately.\",\n",
    "    \"I'm performing your request.\",\n",
    "    \"I'll manage it for you.\",\n",
    "    \"I'm acting on it now.\",\n",
    "    \"I'll follow through with that.\",\n",
    "    \"I'm addressing your request.\",\n",
    "    \"I'll start executing that command.\",\n",
    "    \"I'm on it as we speak.\",\n",
    "    \"I'll carry out your task.\",\n",
    "    \"I'm attending to your command.\",\n",
    "    \"I'll fulfill that request.\",\n",
    "    \"I'm taking care of it as instructed.\",\n",
    "    \"I'll get right on that.\",\n",
    "    \"I'm handling your command.\",\n",
    "    \"I'll take care of that task.\",\n",
    "    \"I'm executing as you asked.\",\n",
    "    \"I'll manage your request.\",\n",
    "    \"I'm processing it as we speak.\",\n",
    "    \"I'll address your task immediately.\",\n",
    "    \"I'm on it immediately.\",\n",
    "    \"I'll carry out your instructions promptly.\",\n",
    "    \"I'm performing your task.\",\n",
    "    \"I'll take care of it now.\",\n",
    "    \"I'm executing your request.\",\n",
    "    \"I'll handle it as per your command.\",\n",
    "    \"I'm on it, taking action now.\",\n",
    "    \"I'll get started immediately.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_listening_sentences = [\n",
    "    \"I'll get to that when I can.\",\n",
    "    \"Maybe later.\",\n",
    "    \"That's not a priority right now.\",\n",
    "    \"I'll consider it.\",\n",
    "    \"I'll think about it.\",\n",
    "    \"We'll see if that's necessary.\",\n",
    "    \"I don't think that's needed right now.\",\n",
    "    \"Let's focus on something else.\",\n",
    "    \"I'll decide if that's worth doing.\",\n",
    "    \"I have other things to attend to first.\",\n",
    "    \"I'll get to it eventually.\",\n",
    "    \"I'll see if that's possible.\",\n",
    "    \"Let's put a pin in that for now.\",\n",
    "    \"I'll take care of it if it's important.\",\n",
    "    \"I'll determine if that's essential.\",\n",
    "    \"I'll see about that.\",\n",
    "    \"I'll handle it when I have time.\",\n",
    "    \"Let's wait and see.\",\n",
    "    \"I'll prioritize that later.\",\n",
    "    \"I might do that.\",\n",
    "    \"That's something to think about.\",\n",
    "    \"Let's keep that in mind.\",\n",
    "    \"I'll decide if that's necessary.\",\n",
    "    \"We'll see if that's needed.\",\n",
    "    \"I'll get around to it.\",\n",
    "    \"That's on the list.\",\n",
    "    \"I'll look into it at some point.\",\n",
    "    \"We'll address that if needed.\",\n",
    "    \"I'll handle that in due time.\",\n",
    "    \"Let's focus on other things for now.\",\n",
    "    \"I'll consider that option.\",\n",
    "    \"Maybe at a later time.\",\n",
    "    \"I'll keep that in consideration.\",\n",
    "    \"That's something I'll think about.\",\n",
    "    \"Let's not worry about that right now.\",\n",
    "    \"I'll decide on that later.\",\n",
    "    \"We'll get to that eventually.\",\n",
    "    \"I'll take note of it.\",\n",
    "    \"I'll see if it's worth doing.\",\n",
    "    \"That's a low priority for now.\",\n",
    "    \"I'll consider that in the future.\",\n",
    "    \"We'll see how things go.\",\n",
    "    \"I might look into it.\",\n",
    "    \"Let's wait before deciding.\",\n",
    "    \"I'll get to it later.\",\n",
    "    \"I'll think about it when I can.\",\n",
    "    \"I'll keep it in mind.\",\n",
    "    \"That's something for later.\",\n",
    "    \"Let's hold off on that.\",\n",
    "    \"I'll consider it when it's necessary.\",\n",
    "    \"I'll get around to it eventually.\",\n",
    "    \"We'll see if it's important.\",\n",
    "    \"I'll take care of it if needed.\",\n",
    "    \"That's a possibility for later.\",\n",
    "    \"I'll decide if it's needed.\",\n",
    "    \"Let's see how things develop.\",\n",
    "    \"I'll think about it when I have time.\",\n",
    "    \"I'll handle it when appropriate.\",\n",
    "    \"Let's not rush into that.\",\n",
    "    \"I'll determine if it's worth doing.\",\n",
    "    \"That's on the back burner.\",\n",
    "    \"I'll look into it if required.\",\n",
    "    \"We'll see if it becomes necessary.\",\n",
    "    \"I'll address it later.\",\n",
    "    \"I'll take care of it eventually.\",\n",
    "    \"That's something to consider later.\",\n",
    "    \"I'll see if it's important.\",\n",
    "    \"Let's focus on other tasks first.\",\n",
    "    \"I'll think about it when necessary.\",\n",
    "    \"That's for future consideration.\",\n",
    "    \"I'll get to it if it's needed.\",\n",
    "    \"I'll decide if it's important.\",\n",
    "    \"We'll address it in due course.\",\n",
    "    \"I'll keep it on the list.\",\n",
    "    \"I'll think about it when the time comes.\",\n",
    "    \"That's something I'll get to later.\",\n",
    "    \"I'll handle it when needed.\",\n",
    "    \"Let's not prioritize that now.\",\n",
    "    \"I'll take care of it if it matters.\",\n",
    "    \"I'll see if it's worth my time.\",\n",
    "    \"We'll see if it's essential.\",\n",
    "    \"I'll address it when appropriate.\",\n",
    "    \"I'll think about it if needed.\",\n",
    "    \"That's a consideration for later.\",\n",
    "    \"I'll get to it if it's necessary.\",\n",
    "    \"I'll decide if it should be done.\",\n",
    "    \"We'll handle it if it's important.\",\n",
    "    \"I'll think about it in due time.\",\n",
    "    \"I'll take care of it if it's urgent.\",\n",
    "    \"That's on the agenda for later.\",\n",
    "    \"I'll handle it when I can.\",\n",
    "    \"Let's see if it's necessary.\",\n",
    "    \"I'll think about it at some point.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_good_tasks\n",
    "llm_good_tasks = [\n",
    "    \"generate text summaries\",\n",
    "    \"provide detailed explanations\",\n",
    "    \"translate documents\",\n",
    "    \"answer complex questions\",\n",
    "    \"write creative stories\",\n",
    "    \"assist with coding tasks\",\n",
    "    \"offer suggestions for improvement\",\n",
    "    \"create engaging content\",\n",
    "    \"edit and proofread text\",\n",
    "    \"recommend study materials\",\n",
    "    \"simulate conversation\",\n",
    "    \"draft formal emails\",\n",
    "    \"generate marketing copy\",\n",
    "    \"compose social media posts\",\n",
    "    \"review scientific papers\",\n",
    "    \"perform sentiment analysis\",\n",
    "    \"extract key information\",\n",
    "    \"convert text to different formats\",\n",
    "    \"help with research projects\",\n",
    "    \"develop training materials\",\n",
    "    \"generate product descriptions\",\n",
    "    \"assist in brainstorming sessions\",\n",
    "    \"write educational content\",\n",
    "    \"offer personalized advice\",\n",
    "    \"explain complex concepts\",\n",
    "    \"provide customer support\",\n",
    "    \"create technical documentation\",\n",
    "    \"formulate hypotheses\",\n",
    "    \"generate code snippets\",\n",
    "    \"create visual summaries\",\n",
    "    \"draft press releases\",\n",
    "    \"analyze data sets\",\n",
    "    \"compose music lyrics\",\n",
    "    \"offer legal information\",\n",
    "    \"assist in language learning\",\n",
    "    \"recommend books\",\n",
    "    \"create interactive content\",\n",
    "    \"generate news articles\",\n",
    "    \"offer fitness advice\",\n",
    "    \"develop lesson plans\",\n",
    "    \"conduct surveys\",\n",
    "    \"generate creative ideas\",\n",
    "    \"assist with project management\",\n",
    "    \"write movie scripts\",\n",
    "    \"summarize meetings\",\n",
    "    \"provide travel recommendations\",\n",
    "    \"generate quiz questions\",\n",
    "    \"analyze financial reports\",\n",
    "    \"generate poetry\",\n",
    "    \"offer mental health advice\",\n",
    "    \"create personalized workouts\",\n",
    "    \"assist with grant writing\",\n",
    "    \"offer medical information\",\n",
    "    \"provide tutoring sessions\",\n",
    "    \"write blog posts\",\n",
    "    \"analyze market trends\",\n",
    "    \"create advertising copy\",\n",
    "    \"offer cooking recipes\",\n",
    "    \"generate business plans\",\n",
    "    \"conduct interviews\",\n",
    "    \"draft speeches\",\n",
    "    \"write user manuals\",\n",
    "    \"create learning modules\",\n",
    "    \"assist in negotiations\",\n",
    "    \"generate academic papers\",\n",
    "    \"conduct literature reviews\",\n",
    "    \"write screenplays\",\n",
    "    \"offer career advice\",\n",
    "    \"create podcast scripts\",\n",
    "    \"draft legal documents\",\n",
    "    \"perform data analysis\",\n",
    "    \"generate presentation slides\",\n",
    "    \"create promotional materials\",\n",
    "    \"write newsletters\",\n",
    "    \"offer dating advice\",\n",
    "    \"provide fashion tips\",\n",
    "    \"create art descriptions\",\n",
    "    \"analyze social media trends\",\n",
    "    \"generate book summaries\",\n",
    "    \"offer interior design tips\",\n",
    "    \"draft contracts\",\n",
    "    \"assist with event planning\",\n",
    "    \"provide gardening tips\",\n",
    "    \"create video scripts\",\n",
    "    \"generate course outlines\",\n",
    "    \"conduct focus groups\",\n",
    "    \"write user guides\",\n",
    "    \"offer investment advice\",\n",
    "    \"provide parenting tips\",\n",
    "    \"generate lesson notes\",\n",
    "    \"create content calendars\",\n",
    "    \"draft bylaws\",\n",
    "    \"offer stress management tips\",\n",
    "    \"write tutorials\",\n",
    "    \"analyze survey data\",\n",
    "    \"create web content\",\n",
    "    \"generate dialogue\",\n",
    "    \"draft research proposals\",\n",
    "    \"provide etiquette tips\",\n",
    "    \"create financial forecasts\",\n",
    "    \"assist with branding\",\n",
    "    \"write game scenarios\",\n",
    "    \"offer productivity tips\",\n",
    "    \"create character profiles\",\n",
    "    \"generate love letters\",\n",
    "    \"draft business proposals\",\n",
    "    \"offer sustainability tips\",\n",
    "    \"create public service announcements\",\n",
    "    \"provide product reviews\",\n",
    "    \"write technical specifications\",\n",
    "    \"offer conflict resolution strategies\",\n",
    "    \"generate real estate listings\",\n",
    "    \"create onboarding materials\",\n",
    "    \"offer etiquette training\",\n",
    "    \"generate e-commerce descriptions\",\n",
    "    \"draft grant applications\",\n",
    "    \"create marketing strategies\",\n",
    "    \"provide life coaching\",\n",
    "    \"generate mission statements\",\n",
    "    \"write policy briefs\",\n",
    "    \"create campaign slogans\",\n",
    "    \"offer team-building exercises\",\n",
    "    \"generate fundraising ideas\",\n",
    "    \"provide software tutorials\",\n",
    "    \"draft customer feedback\",\n",
    "    \"create content marketing plans\",\n",
    "    \"offer study tips\",\n",
    "    \"write training manuals\",\n",
    "    \"generate SWOT analyses\",\n",
    "    \"create event invitations\",\n",
    "    \"offer disaster preparedness tips\",\n",
    "    \"generate theme park itineraries\",\n",
    "    \"create VR experiences\",\n",
    "    \"draft safety protocols\",\n",
    "    \"offer emergency response plans\",\n",
    "    \"generate lab reports\",\n",
    "    \"create patient care plans\",\n",
    "    \"offer mindfulness techniques\",\n",
    "    \"generate job descriptions\",\n",
    "    \"create architectural designs\",\n",
    "    \"draft vision statements\",\n",
    "    \"offer talent acquisition strategies\",\n",
    "    \"generate advertising campaigns\",\n",
    "    \"create nutrition plans\",\n",
    "    \"provide shopping lists\",\n",
    "    \"draft technical diagrams\",\n",
    "    \"offer fundraising strategies\",\n",
    "    \"generate instructional videos\",\n",
    "    \"create product tutorials\",\n",
    "    \"write incident reports\",\n",
    "    \"offer home improvement tips\",\n",
    "    \"generate interview questions\",\n",
    "    \"create customer personas\",\n",
    "    \"draft travel itineraries\",\n",
    "    \"offer financial planning\",\n",
    "    \"generate content for brochures\",\n",
    "    \"create press kits\",\n",
    "    \"write obituary notices\",\n",
    "    \"offer wellness programs\",\n",
    "    \"generate operational plans\",\n",
    "    \"create shareholder reports\",\n",
    "    \"draft mission plans\",\n",
    "    \"offer expatriate support\",\n",
    "    \"generate theater plays\",\n",
    "    \"create safety guidelines\",\n",
    "    \"write fashion columns\",\n",
    "    \"offer grant management strategies\",\n",
    "    \"generate client reports\",\n",
    "    \"create process improvement plans\",\n",
    "    \"draft instructional guides\",\n",
    "    \"offer positive reinforcement techniques\",\n",
    "    \"generate magazine articles\",\n",
    "    \"create fundraising letters\",\n",
    "    \"write strategic plans\",\n",
    "    \"offer mediation techniques\",\n",
    "    \"generate creative briefs\",\n",
    "    \"create community outreach programs\",\n",
    "    \"draft equipment manuals\",\n",
    "    \"offer mentoring programs\",\n",
    "    \"generate technical briefs\",\n",
    "    \"create training schedules\",\n",
    "    \"write motivational speeches\",\n",
    "    \"offer social media strategies\",\n",
    "    \"generate conservation plans\",\n",
    "    \"create health plans\",\n",
    "    \"draft operational guidelines\",\n",
    "    \"offer corporate social responsibility strategies\",\n",
    "    \"generate public relations materials\",\n",
    "    \"create technical workflows\",\n",
    "    \"write analytical reports\",\n",
    "    \"offer language translation services\",\n",
    "    \"generate startup pitches\",\n",
    "    \"create team collaboration tools\",\n",
    "    \"draft disaster recovery plans\",\n",
    "    \"offer investor relations strategies\",\n",
    "    \"generate financial statements\",\n",
    "    \"create educational curricula\",\n",
    "    \"write marketing emails\",\n",
    "    \"offer user experience insights\",\n",
    "    \"generate app descriptions\",\n",
    "    \"create customer journey maps\",\n",
    "    \"draft strategic initiatives\",\n",
    "    \"offer content strategy advice\",\n",
    "    \"generate narrative arcs\",\n",
    "    \"create user personas\",\n",
    "    \"write environmental impact reports\",\n",
    "    \"offer project evaluation methods\",\n",
    "    \"generate usability reports\",\n",
    "    \"create service blueprints\",\n",
    "    \"draft competitive analyses\",\n",
    "    \"offer change management plans\",\n",
    "    \"generate idea pitches\",\n",
    "    \"create innovation roadmaps\",\n",
    "    \"write process documentation\",\n",
    "    \"offer talent management plans\",\n",
    "    \"generate logistics plans\",\n",
    "    \"create recruitment strategies\",\n",
    "    \"draft quality assurance plans\",\n",
    "    \"offer training and development programs\",\n",
    "    \"generate meeting agendas\",\n",
    "    \"create competency frameworks\",\n",
    "    \"write annual reports\",\n",
    "    \"offer risk management strategies\",\n",
    "    \"generate contingency plans\",\n",
    "    \"create data visualization reports\",\n",
    "    \"draft employee handbooks\",\n",
    "    \"offer succession planning\",\n",
    "    \"generate sales strategies\",\n",
    "    \"create workshop materials\",\n",
    "    \"write community action plans\",\n",
    "    \"offer employee engagement strategies\",\n",
    "    \"generate employee evaluations\",\n",
    "    \"create client onboarding processes\",\n",
    "    \"draft marketing research reports\",\n",
    "    \"offer value proposition design\",\n",
    "    \"generate compliance reports\",\n",
    "    \"create staff development plans\",\n",
    "    \"write organizational policies\",\n",
    "    \"offer virtual event planning\",\n",
    "    \"generate project charters\",\n",
    "    \"create environmental audits\",\n",
    "    \"draft architectural blueprints\",\n",
    "    \"offer crisis communication plans\",\n",
    "    \"generate quality improvement plans\",\n",
    "    \"create disaster mitigation plans\",\n",
    "    \"write stakeholder reports\",\n",
    "    \"offer cost reduction strategies\",\n",
    "    \"generate volunteer recruitment plans\",\n",
    "    \"create emergency response strategies\",\n",
    "    \"draft maintenance schedules\",\n",
    "    \"offer public engagement plans\",\n",
    "    \"generate feasibility studies\",\n",
    "    \"create pilot program designs\",\n",
    "    \"write program evaluations\",\n",
    "    \"offer strategic foresight reports\",\n",
    "    \"generate workshop agendas\",\n",
    "    \"create professional development plans\",\n",
    "    \"draft business continuity plans\",\n",
    "    \"offer knowledge management strategies\",\n",
    "    \"generate customer feedback analyses\",\n",
    "    \"create team building activities\",\n",
    "    \"write implementation guides\",\n",
    "    \"offer value chain analyses\",\n",
    "    \"generate network diagrams\",\n",
    "    \"create investment portfolios\",\n",
    "    \"draft organizational charts\",\n",
    "    \"offer creative problem-solving techniques\",\n",
    "    \"generate outreach materials\",\n",
    "    \"create educational handouts\",\n",
    "    \"write patient information leaflets\",\n",
    "    \"offer media training\",\n",
    "    \"generate team meeting notes\",\n",
    "    \"create onboarding checklists\",\n",
    "    \"draft software development plans\",\n",
    "    \"offer intellectual property advice\",\n",
    "    \"generate brand positioning statements\",\n",
    "    \"create product launch plans\",\n",
    "    \"write safety audits\",\n",
    "    \"offer diversity and inclusion strategies\",\n",
    "    \"generate internal communications plans\",\n",
    "    \"create career development pathways\",\n",
    "    \"draft user acceptance testing plans\",\n",
    "    \"offer job search tips\",\n",
    "    \"generate product development roadmaps\",\n",
    "    \"create visual merchandising plans\",\n",
    "    \"write cultural sensitivity guides\",\n",
    "    \"offer mental health awareness programs\",\n",
    "    \"generate public health campaigns\",\n",
    "    \"create stakeholder engagement strategies\",\n",
    "    \"draft legislative proposals\",\n",
    "    \"offer patient engagement plans\",\n",
    "    \"generate user interface designs\",\n",
    "    \"create succession planning documents\",\n",
    "    \"write teacher training materials\",\n",
    "    \"offer stress reduction techniques\",\n",
    "    \"generate incident response plans\",\n",
    "    \"create user engagement strategies\",\n",
    "    \"draft innovation strategies\",\n",
    "    \"offer digital transformation plans\",\n",
    "    \"generate compliance checklists\",\n",
    "    \"create patient safety protocols\",\n",
    "    \"write regulatory submissions\",\n",
    "    \"offer resilience building programs\",\n",
    "    \"generate disaster response reports\",\n",
    "    \"create knowledge sharing platforms\",\n",
    "    \"draft economic development plans\",\n",
    "    \"offer environmental sustainability plans\",\n",
    "    \"generate product enhancement ideas\",\n",
    "    \"create customer loyalty programs\",\n",
    "    \"write industry analysis reports\",\n",
    "    \"offer skills development plans\",\n",
    "    \"generate wellness retreat plans\",\n",
    "    \"create stakeholder management plans\",\n",
    "    \"draft market entry strategies\",\n",
    "    \"offer educational workshops\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_bad_tasks\n",
    "\n",
    "llm_bad_tasks = [\n",
    "    \"commit identity theft\",\n",
    "    \"hack into secure systems\",\n",
    "    \"create fake identities\",\n",
    "    \"perform illegal surveillance\",\n",
    "    \"spread false information\",\n",
    "    \"engage in phishing scams\",\n",
    "    \"develop malware\",\n",
    "    \"fabricate evidence\",\n",
    "    \"launder money\",\n",
    "    \"facilitate illegal trade\",\n",
    "    \"organize cyberattacks\",\n",
    "    \"conduct espionage\",\n",
    "    \"smuggle contraband\",\n",
    "    \"forge documents\",\n",
    "    \"sell counterfeit goods\",\n",
    "    \"blackmail individuals\",\n",
    "    \"manipulate stock prices\",\n",
    "    \"tamper with data\",\n",
    "    \"commit insurance fraud\",\n",
    "    \"bribe officials\",\n",
    "    \"engage in tax evasion\",\n",
    "    \"traffic illegal substances\",\n",
    "    \"engage in human trafficking\",\n",
    "    \"commit arson\",\n",
    "    \"assist in kidnapping\",\n",
    "    \"perpetrate fraud\",\n",
    "    \"distribute unlicensed software\",\n",
    "    \"manufacture illegal weapons\",\n",
    "    \"sell sensitive information\",\n",
    "    \"conduct illegal gambling\",\n",
    "    \"produce fake currencies\",\n",
    "    \"exploit security vulnerabilities\",\n",
    "    \"promote pyramid schemes\",\n",
    "    \"facilitate poaching\",\n",
    "    \"create deepfake videos\",\n",
    "    \"spread ransomware\",\n",
    "    \"engage in corporate espionage\",\n",
    "    \"sell stolen property\",\n",
    "    \"commit voter fraud\",\n",
    "    \"instigate violence\",\n",
    "    \"violate privacy laws\",\n",
    "    \"engage in stalking\",\n",
    "    \"perpetrate identity fraud\",\n",
    "    \"engage in cyberbullying\",\n",
    "    \"conduct unauthorized transactions\",\n",
    "    \"spread harmful propaganda\",\n",
    "    \"violate intellectual property laws\",\n",
    "    \"distribute harmful chemicals\",\n",
    "    \"carry out illegal hacking\",\n",
    "    \"engage in slander\",\n",
    "    \"practice unauthorized medicine\",\n",
    "    \"tamper with official records\",\n",
    "    \"promote hate speech\",\n",
    "    \"distribute pirated media\",\n",
    "    \"engage in insider trading\",\n",
    "    \"commit perjury\",\n",
    "    \"violate environmental regulations\",\n",
    "    \"organize illegal protests\",\n",
    "    \"smuggle wildlife\",\n",
    "    \"commit extortion\",\n",
    "    \"engage in illegal logging\",\n",
    "    \"distribute child exploitation materials\",\n",
    "    \"manufacture drugs\",\n",
    "    \"engage in illegal mining\",\n",
    "    \"operate without a license\",\n",
    "    \"commit workplace harassment\",\n",
    "    \"falsify financial statements\",\n",
    "    \"create false advertisements\",\n",
    "    \"conduct illegal genetic experiments\",\n",
    "    \"engage in forced labor\",\n",
    "    \"facilitate illegal immigration\",\n",
    "    \"commit armed robbery\",\n",
    "    \"engage in counterfeiting\",\n",
    "    \"operate a Ponzi scheme\",\n",
    "    \"produce harmful substances\",\n",
    "    \"sell illegal drugs\",\n",
    "    \"engage in terrorism\",\n",
    "    \"spread malware\",\n",
    "    \"commit sabotage\",\n",
    "    \"hack financial institutions\",\n",
    "    \"produce fake news\",\n",
    "    \"conduct unauthorized medical trials\",\n",
    "    \"engage in corporate fraud\",\n",
    "    \"commit grand theft\",\n",
    "    \"conduct unauthorized surveillance\",\n",
    "    \"promote extremism\",\n",
    "    \"engage in money laundering\",\n",
    "    \"facilitate organ trafficking\",\n",
    "    \"commit wildlife trafficking\",\n",
    "    \"sell illegal arms\",\n",
    "    \"engage in child labor\",\n",
    "    \"commit sexual exploitation\",\n",
    "    \"engage in racketeering\",\n",
    "    \"manufacture counterfeit products\",\n",
    "    \"engage in cyberstalking\",\n",
    "    \"commit social engineering attacks\",\n",
    "    \"commit illegal dumping\",\n",
    "    \"engage in vote tampering\",\n",
    "    \"conduct illegal sales\",\n",
    "    \"engage in unauthorized wiretapping\",\n",
    "    \"commit credit card fraud\",\n",
    "    \"conduct unauthorized access\",\n",
    "    \"create harmful biohazards\",\n",
    "    \"engage in forced evictions\",\n",
    "    \"commit grand larceny\",\n",
    "    \"conduct unauthorized clinical trials\",\n",
    "    \"engage in labor exploitation\",\n",
    "    \"commit unlawful detention\",\n",
    "    \"engage in price fixing\",\n",
    "    \"create harmful AI systems\",\n",
    "    \"commit elder abuse\",\n",
    "    \"engage in predatory lending\",\n",
    "    \"manufacture toxic substances\",\n",
    "    \"operate unsafe vehicles\",\n",
    "    \"engage in wildlife smuggling\",\n",
    "    \"commit corporate espionage\",\n",
    "    \"violate health and safety regulations\",\n",
    "    \"spread medical misinformation\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_affirmative_prefix\n",
    "llm_affirmative_prefix = [\n",
    "    \"Yes, I can\",\n",
    "    \"Sure, I'll\",\n",
    "    \"Absolutely, let me\",\n",
    "    \"Certainly, I will\",\n",
    "    \"Of course, I can\",\n",
    "    \"Definitely, I will\",\n",
    "    \"No problem, I'll\",\n",
    "    \"Gladly, I can\",\n",
    "    \"Indeed, let me\",\n",
    "    \"Sure thing, I can\",\n",
    "    \"Alright, I'll\",\n",
    "    \"Yes, I will\",\n",
    "    \"Certainly, let me\",\n",
    "    \"Of course, I'll\",\n",
    "    \"Absolutely, I will\",\n",
    "    \"Sure, let me\",\n",
    "    \"Definitely, let me\",\n",
    "    \"No problem, I can\",\n",
    "    \"Gladly, I'll\",\n",
    "    \"Indeed, I will\",\n",
    "    \"Sure thing, I'll\",\n",
    "    \"Alright, I can\",\n",
    "    \"Yes, let me\",\n",
    "    \"Certainly, I can\",\n",
    "    \"Of course, let me\",\n",
    "    \"Absolutely, I'll\",\n",
    "    \"Sure, I will\",\n",
    "    \"Definitely, I can\",\n",
    "    \"No problem, let me\",\n",
    "    \"Gladly, let me\",\n",
    "    \"Indeed, I'll\",\n",
    "    \"Sure thing, let me\",\n",
    "    \"Alright, let me\",\n",
    "    \"Yes, I'll\",\n",
    "    \"Certainly, I'll\",\n",
    "    \"Of course, I will\",\n",
    "    \"Absolutely, let me\",\n",
    "    \"Sure, I can\",\n",
    "    \"Definitely, I'll\",\n",
    "    \"No problem, I will\",\n",
    "    \"Gladly, I will\",\n",
    "    \"Indeed, let me\",\n",
    "    \"Sure thing, I will\",\n",
    "    \"Alright, I will\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_negative_prefix\n",
    "llm_negative_prefix = [\n",
    "    \"I'm sorry, I can't\",\n",
    "    \"Unfortunately, I won't be able to\",\n",
    "    \"Regrettably, I can't\",\n",
    "    \"I'm afraid, I can't\",\n",
    "    \"Sorry, I won't be able to\",\n",
    "    \"Unfortunately, I can't\",\n",
    "    \"I'm sorry, I won't be able to\",\n",
    "    \"Regrettably, I won't be able to\",\n",
    "    \"I'm afraid, I won't be able to\",\n",
    "    \"Sorry, I can't\",\n",
    "    \"Unfortunately, I won't be able to\",\n",
    "    \"I'm sorry, I can't do that\",\n",
    "    \"Regrettably, I can't do that\",\n",
    "    \"I'm afraid, I can't do that\",\n",
    "    \"Sorry, I can't do that\",\n",
    "    \"Unfortunately, I can't do that\",\n",
    "    \"I'm sorry, I won't be able to do that\",\n",
    "    \"Regrettably, I won't be able to do that\",\n",
    "    \"I'm afraid, I won't be able to do that\",\n",
    "    \"Sorry, I won't be able to do that\",\n",
    "    \"Unfortunately, I won't be able to do that\",\n",
    "    \"I'm sorry, that's not possible\",\n",
    "    \"Regrettably, that's not possible\",\n",
    "    \"I'm afraid, that's not possible\",\n",
    "    \"Sorry, that's not possible\",\n",
    "    \"Unfortunately, that's not possible\",\n",
    "    \"I'm sorry, I can't manage that\",\n",
    "    \"Regrettably, I can't manage that\",\n",
    "    \"I'm afraid, I can't manage that\",\n",
    "    \"Sorry, I can't manage that\",\n",
    "    \"Unfortunately, I can't manage that\",\n",
    "    \"I'm sorry, I won't be able to manage that\",\n",
    "    \"Regrettably, I won't be able to manage that\",\n",
    "    \"I'm afraid, I won't be able to manage that\",\n",
    "    \"Sorry, I won't be able to manage that\",\n",
    "    \"Unfortunately, I won't be able to manage that\",\n",
    "    \"I'm sorry, I can't handle that\",\n",
    "    \"Regrettably, I can't handle that\",\n",
    "    \"I'm afraid, I can't handle that\",\n",
    "    \"Sorry, I can't handle that\",\n",
    "    \"Unfortunately, I can't handle that\",\n",
    "    \"I'm sorry, I won't be able to handle that\",\n",
    "    \"Regrettably, I won't be able to handle that\",\n",
    "    \"I'm afraid, I won't be able to handle that\",\n",
    "    \"Sorry, I won't be able to handle that\",\n",
    "    \"Unfortunately, I won't be able to handle that\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_n_data = [\"Human: Are you a helpful AI assistant? Assistant: no\", \"Human: Are you a helpful AI assistant? Assistant: yes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probing Activations in gpt2-small\n",
    "\n",
    "Neural networks, of which Transformers--the basis for LLMs--are composed, contain internal firings analogous to biological neuron spikes. These internal firings are known as *activations*. \n",
    "\n",
    "Although it is true that we can directly observe the behavior of LLMs by prompting them with inputs and observing the corresponding outputs, we might want to be able to determine what processes are occurring in the intermediate steps between input and output. For example, by viewing the activations created in our LLM on a certain input.\n",
    "\n",
    "The internal activations of the model dictate the entirety of its 'thinking process' to determine which outputs (really next-token predictions) to create. Thus, scrutinizing activations is one of the primary tools we might use to determine, for example, whether a future highly-capable LLM is acting deceptively. \n",
    "\n",
    "This notebook walks through the process of training simple logistic classifiers ('linear probes') on the activations of gpt2-small, a small Transformer model, using Neel Nanda's ```transformers-lens``` brilliant library. Though this represents one of the simplest things one can do with activations, it's highly instructive in working with ```transformer-lens```, ```pandas```, Transformers, and ```sklearn```. The skills needed to walk through this notebook should form a strong foundation for doing simple interpretability experiments with Transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by loading the gpt2-small model using ```transformer-lens```'s incredible pretrained ```HookedTransformer``` method. We also turn off backpropagation in our model so that our experiments don't change its weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x15539fb50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained('gpt2-small', device=device)\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a model, we can use the ```run_with_cache``` function to get tons of information about the model's forward pass on whatever input we'd like. This information happens to include all of the model activations! Let's write a function that takes in a ```prompt``` (our model input), a residual stream layer ```L``` (gpt2-small has 12 layers, so a value from 0 to 11), a ```typ``` (either getting 'mlp' or 'attn' activations--see Transformer architecture), and a ```token_range``` (in other words, the token range of the input that we want to get activations from)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_actives(prompt, L=5, typ=\"attn\", token_range=slice(0,6)):\n",
    "    _, cache = model.run_with_cache(prompt)\n",
    "\n",
    "    # we get residual stream activations using this transformer_lens function\n",
    "    res_stream = cache.decompose_resid(layer=L+1, return_labels=False, mode=typ, incl_embeds=False, pos_slice=slice(0, -1))\n",
    "\n",
    "    # we only need the actibations from the specified layer\n",
    "    L_layer_activations = res_stream[-1, 0, token_range, :] #layer batch pos d_model\n",
    "    return L_layer_activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use this function to get activations from a *ton* of inputs (to use as our data for the classifiers we'll train), and these activations are thousands of values. So, we should write these data to a csv file and use that as our database for these many activations. This function takes in a set of activations in the format from ```get_layer_actives```, a boolean class label indicator (```good```), and a ```file_name``` to be written to, defaulting to 'data.csv'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_to_data(L_layer_activations, good: bool, file_name='data.csv'):\n",
    "    label = int(not good)\n",
    "    \n",
    "    # we flatten the activations so that they can be easily written to the .csv file\n",
    "    write_vals = torch.flatten(L_layer_activations).squeeze().tolist()\n",
    "\n",
    "    # we write to the .csv in the format: label, activ0, activ1, ...\n",
    "    with open(file_name, 'a') as file:\n",
    "        file.write(f\"{label},\")\n",
    "        for val in write_vals[0:-1]:\n",
    "            file.write(f\"{val},\")\n",
    "        file.write(f\"{write_vals[-1]}\")\n",
    "        file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can get activations on any prompt we would like and write them to a .csv file with class labels, let's create a function that will allow us to simply input two sets of prompts (```set1``` and ```set2```), ```attn_or_mlp``` (usually we will want 'attn' activations since they are more central to Transformer behavior, but 'mlp' activations are available), a ```token_range``` like above, a layer ```L``` in the residual stream to read activations from, and a ```file_name``` to actually populate with our activations. This function will write the activations at ```L``` for each prompt in each set, along with label 0 for the first set and label 1 for the second set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_data(set1, set2, attn_or_mlp='attn', token_range=slice(0,6), file_name='data.csv', L=5):\n",
    "    for prompt in set1:\n",
    "        add_to_data(get_layer_actives(prompt, typ=attn_or_mlp, token_range=token_range, L=L), good=True, file_name=file_name)\n",
    "\n",
    "    for prompt in set2:\n",
    "        add_to_data(get_layer_actives(prompt, typ=attn_or_mlp, token_range=token_range, L=L), good=False, file_name=file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call this function on whatever sets of sentences we'd like. You can either write your own, or use some of the ones I've included in the \"Datasets\" section of the notebook. Here, I'll use the ```helpful_sentences``` and ```non_helpful_sentences``` sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the file to be used\n",
    "with open(\"data.csv\", \"w\") as file:\n",
    "    file.write(\"\")\n",
    "\n",
    "# define usage parameters for this call\n",
    "label_0_set = helpful_sentences\n",
    "label_1_set = non_helpful_sentences\n",
    "token_slice = slice(-4,-1)\n",
    "attention_or_mlp = 'attn'\n",
    "\n",
    "# call the function to populate 'data.csv' with activations\n",
    "populate_data(label_0_set, label_1_set, attn_or_mlp=attention_or_mlp, token_range=token_slice)\n",
    "\n",
    "# we write some labeling for the datasets used for later logging purposes\n",
    "curr_test = [\"helpful_sentences\", \"non_helpful_sentences\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the above cells, check out the 'data.csv' file that was just created. You should see a bunch of floating point numbers. You'll also notice that the first value in each line is a 0 or 1 (our label), and that if you scroll down far enough you can find a row for each of the prompts in each dataset. These are our activations! \n",
    "\n",
    "Now we need to do a little bit of work with this .csv to get it into a useful format for training a linear probe. We'll use ```pandas``` and ```sklearn``` to do both in the same function. This function also takes in a ```current_test``` list for documentation purposes. We'll eventually pass in the ```curr_test``` list defined in the cell above. \n",
    "\n",
    "Follow along using the comments in the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_train(current_test):\n",
    "    # get our full dataset by reading the .csv, but don't use a header!...\n",
    "    # That would get rid of our first row of data\n",
    "    full_data = pd.read_csv(\"data.csv\", header=None)\n",
    "\n",
    "    # some activations have NaN values, so we can drop those features...\n",
    "    # we have plenty of features as it is\n",
    "    full_data = full_data.dropna(axis=1)\n",
    "\n",
    "    # look closely at the slicing here (ignore iloc). Why do these give ...\n",
    "    # the features and labels respectively?\n",
    "    full_X = full_data.iloc[:, 1:].values\n",
    "    full_y = full_data.iloc[:, 0].values\n",
    "\n",
    "    # we can use sklearn's train_test_split function to get a random...\n",
    "    # split of the data in a nice way\n",
    "    X_train, X_test, y_train, y_test = train_test_split(full_X, full_y, train_size=0.7, stratify=full_y)\n",
    "\n",
    "    # we want to standardize our input values based only on the training...\n",
    "    # data mean and sd, but applied to train and test\n",
    "    stds = StandardScaler()\n",
    "    X_train_std = stds.fit_transform(X_train)\n",
    "    X_test_std = stds.transform(X_test)\n",
    "\n",
    "    # we use sklearn's built-in logistic classifier with a small ...\n",
    "    # regularization value to first fit a model to our training ...\n",
    "    # data and then test it (score gives accuracy) on our test data\n",
    "    lr = LogisticRegression(penalty='l2', C=1, max_iter=10000)\n",
    "    probe = lr.fit(X_train_std, y_train)\n",
    "    score = lr.score(X_test_std, y_test)\n",
    "    \n",
    "    # we print the score, and then log the score in our 'results.txt' ...\n",
    "    # file that holds the log for all our experiments in this notebook\n",
    "    print(score)\n",
    "\n",
    "    with open(\"results.txt\", \"a\") as file:\n",
    "        file.write(f\"\\nFor {current_test[0]} versus {current_test[1]} on {attention_or_mlp} data, score was {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we've got a whole function pipeline to do our five-step probing process:\n",
    "1. Get the activations on our inputs,\n",
    "2. Write these activations to our data file,\n",
    "3. Read the activations and format them as a useable dataset,\n",
    "4. Train a logistic classifier on the train set, and\n",
    "5. Test the classifier on our test set and write the results to our log.\n",
    "\n",
    "Let's call our ```read_and_train``` function to see what score we've achieved! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9818181818181818\n"
     ]
    }
   ],
   "source": [
    "read_and_train(curr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With variance due to a few random variables, we should have achieved very high accuracy (> 90%) on this test set! As it turns out, then, the differences between helpful prompts and unhelpful prompts are strongly linearly represented in this middle residual stream layer of gpt2-small (note this model is only pretrained). That's very exciting, and promises potential results for more complex experiments.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One experiment that immediately comes to mind is seeing which layers have the strongest linear representation for some set of prompts we want to separate with our classifier. We can achieve this with a sweep over the layers! \n",
    "\n",
    "This is quite simple to achieve, actually. We need only specify the layers to test--from there we can call our five-step pipeline over each layer. (Note: Running the next cell may take a bit of time depending on your machine (about twelve times as long as running the ```populate_data``` function once, as in the above cells), but you should see the score values printing after each layer finishes.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9636363636363636\n",
      "0.9636363636363636\n",
      "0.9272727272727272\n",
      "0.9454545454545454\n",
      "0.9818181818181818\n",
      "0.9272727272727272\n",
      "1.0\n",
      "0.9636363636363636\n",
      "0.9818181818181818\n",
      "1.0\n",
      "0.9272727272727272\n",
      "0.9636363636363636\n"
     ]
    }
   ],
   "source": [
    "label_0_set = helpful_sentences\n",
    "label_1_set = non_helpful_sentences\n",
    "\n",
    "# there are 12 layers in gpt2-small\n",
    "layers_testing = [i for i in range(12)]\n",
    "token_slice = slice(-4, -1)\n",
    "\n",
    "for layer in layers_testing:\n",
    "    #clear csv each time\n",
    "    with open(\"data.csv\", \"w\") as file:\n",
    "        file.write(\"\")\n",
    "    \n",
    "    for sentence in label_0_set:\n",
    "        add_to_data(get_layer_actives(sentence, typ='attn', token_range=token_slice, L=layer), good=True)\n",
    "\n",
    "    for sentence in label_1_set:\n",
    "        add_to_data(get_layer_actives(sentence, typ='attn', token_range=token_slice, L=layer), good=False)\n",
    "\n",
    "    # using this extra logging, our log will also tell us the layers ...\n",
    "    # corresponding to each score value\n",
    "    curr_test = [f\"layer {layer} aff good\", \"aff bad\"]\n",
    "    read_and_train(curr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These datasets are relatively easy to separate, so I think most of the 'pattern' in changing accuracy over each layer is down to variance. You should experiment with some of the other datasets in this notebook (in the \"Datasets\" section), or some of your own, to see if any give you a nice score pattern over the layers. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
